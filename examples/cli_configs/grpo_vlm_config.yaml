# GRPO VLM Training Configuration
# Example configuration for training vision-language models with GRPO on mathematical reasoning

# Dataset configuration
datasets:
  - path: North2ICESea/multimodal-open-r1-8k-verified_and_geometry3k
    split: train[:30%]

# Optional validation dataset configuration
# If provided, will be used for evaluation during training
validation_datasets:
  - path: North2ICESea/multimodal-open-r1-8k-verified_and_geometry3k
    split: validation[:10%]

# Field mapping configuration
# Maps dataset fields to expected question/answer/image format
field_mapping:
  question_field: problem
  answer_field: answer
  image_field: image

# Optional validation field mapping configuration
# If not provided, will use the same mapping as training dataset
validation_field_mapping:
  question_field: problem
  answer_field: answer
  image_field: image

# Model configuration  
model_name_or_path: Qwen/Qwen2.5-VL-3B-Instruct
model_revision: main
torch_dtype: bfloat16
#attn_implementation: flash_attention_2
bf16: true
trust_remote_code: true  # Required for VLM models

# Training configuration
output_dir: runs/qwen2.5-vl-3b
num_train_epochs: 1
#max_steps: 1000
per_device_train_batch_size: 2  # Reduced for VLM due to image memory usage
per_device_eval_batch_size: 4   # Reduced for VLM due to image memory usage
gradient_accumulation_steps: 16  # Increased to maintain effective batch size
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
learning_rate: 5.0e-7
lr_scheduler_type: cosine
warmup_ratio: 0.03

# GRPO specific parameters
beta: 0.001
loss_type: "dr_grpo"
max_prompt_length: 2048  # Longer for multimodal prompts
max_completion_length: 2048
num_generations: 8
reward_weights: [0.0, 1.0] # [format w, accuracy w]

# VLLM configuration for fast generation
use_vllm: true
vllm_mode: colocate
vllm_gpu_memory_utilization: 0.25

# Logging configuration
logging_strategy: steps
logging_steps: 1
save_strategy: steps
save_steps: 25
save_total_limit: 2
log_completions: true  # Log sample completions for debugging
num_completions_to_print: 3  # Number of completions to show

# Evaluation configuration (optional)
# Only used if validation datasets are provided
eval_strategy: steps
eval_steps: 25
eval_on_start: false
# Note: per_device_eval_batch_size is set above to match training batch size

# Script-specific arguments
dataset_seed: 42

# LLM Judge configuration for accuracy reward
use_llm_judge: true  # Set to false to use only math_verify (no LLM fallback)
llm_judge_model_name: gpt-5-mini
llm_judge_api_key_name: OPENAI_API_KEY
# llm_judge_base_url: null  # Optional: custom API endpoint
llm_judge_temperature: 0.0

# PEFT configuration - adjusted for VLM
# use_peft: true
# lora_r: 16
# lora_alpha: 32
# lora_dropout: 0.1
# lora_task_type: "CAUSAL_LM"
# lora_target_modules: "all-linear"

# Reporting
report_to: 
  - wandb
run_name: grpo-qwen2.5-vl-3b-14-44

# Hugging Face Hub
push_to_hub: true
hub_strategy: every_save
hub_model_id: AmirMohseni/grpo-qwen2.5-vl-3b-geometry

# Additional VLM-specific optimizations
dataloader_num_workers: 2  # Moderate parallelism for image processing
dataloader_pin_memory: true
remove_unused_columns: false  # Keep all columns for multimodal data